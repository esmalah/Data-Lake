{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqS3ebg9r9To"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "# Chargement des fichiers\n",
        "bikes_df = pd.read_csv('/content/bikes.csv', delimiter=';')\n",
        "bikeshops_df = pd.read_csv('/content/bikeshops.csv', delimiter=';')\n",
        "orders_df = pd.read_csv('/content/orders.csv', delimiter=';')\n",
        "customers_df = pd.read_csv('/content/Customers.csv', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure entre les commandes (orders) et les vélos (bikes) sur 'product.id' et 'bike.id'\n",
        "orders_bikes_df = pd.merge(orders_df, bikes_df, left_on='product.id', right_on='bike.id')\n"
      ],
      "metadata": {
        "id": "Vtgz26_kssYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_bikes_df['ID'] = range(1, len(orders_bikes_df) + 1)\n",
        "orders_bikes_df= orders_bikes_df.reset_index(drop=True)\n",
        "orders_bikes_df = orders_bikes_df.set_index('ID')\n",
        "orders_bikes_df = orders_bikes_df.drop(columns=['Unnamed: 0'])\n",
        "\n"
      ],
      "metadata": {
        "id": "XqQ_taHes4pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure entre les commandes (orders) et  les clients (customers) sur 'product.id' et 'bike.id'\n",
        "orders_customers_df = pd.merge(orders_df, customers_df, left_on='customer.id', right_on='CustomerKey', how='left')\n"
      ],
      "metadata": {
        "id": "LtM0J4fPs8_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure entre les deux tables résultantes sur 'order.id', 'order.line','order.date','product.id\n",
        "df_merged = pd.merge(orders_customers_df, orders_bikes_df, on=['order.id', 'order.line','order.date','product.id'], how='inner')"
      ],
      "metadata": {
        "id": "WZ37BzsVs9ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df_merged.T.drop_duplicates().T\n",
        "df_merged = df_merged.drop(columns=['Unnamed: 0'])\n",
        "df=df_merged"
      ],
      "metadata": {
        "id": "w4Ax6xfktHnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traitement des valeurs manquantes"
      ],
      "metadata": {
        "id": "VheSELQvtQEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTsGr7EvtKMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df\n",
        "\n",
        "# Vérification des valeurs manquantes dans le dataset\n",
        "missing_values_summary = data.isnull().sum()\n",
        "\n",
        "# Création d'un DataFrame pour afficher les colonnes avec des valeurs manquantes et leur pourcentage\n",
        "missing_values_df = pd.DataFrame({\n",
        "    'Column': missing_values_summary.index,\n",
        "    'Missing Values': missing_values_summary.values,\n",
        "    'Percentage': (missing_values_summary.values / len(data)) * 100\n",
        "})\n",
        "\n",
        "# Filtrage pour afficher seulement les colonnes ayant des valeurs manquantes\n",
        "missing_values_filtered = missing_values_df[missing_values_df['Missing Values'] > 0]\n",
        "print(\"Résumé des valeurs manquantes :\")\n",
        "print(missing_values_filtered)\n",
        "\n",
        "# Identification des colonnes numériques et catégorielles\n",
        "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Imputation des colonnes numériques (avec la moyenne) et des colonnes catégorielles (avec le mode)\n",
        "for col in numeric_cols:\n",
        "    if col in missing_values_filtered['Column'].values:\n",
        "        data[col].fillna(data[col].mean(), inplace=True)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in missing_values_filtered['Column'].values:\n",
        "        data[col].fillna(data[col].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdb9OT5IwFEt",
        "outputId": "c5b68b95-da0c-47d0-b62a-10b63677a322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résumé des valeurs manquantes :\n",
            "Empty DataFrame\n",
            "Columns: [Column, Missing Values, Percentage]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traitement des doublons"
      ],
      "metadata": {
        "id": "G1g1kp0dvXBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nombre de doublons avant suppression : {data.duplicated().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXgpZvmxtguS",
        "outputId": "3ef82ab2-7225-41c3-a672-9d186c139186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de doublons avant suppression : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traitement des valeurs abberantes"
      ],
      "metadata": {
        "id": "Y-3TFrhgvyQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition d'une fonction qui détecte les valeurs aberrantes en utilisant l'écart interquartile (IQR)\n",
        "def detect_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)  # Premier quartile\n",
        "    Q3 = df[column].quantile(0.75)  # Troisième quartile\n",
        "    IQR = Q3 - Q1  # Écart interquartile\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identification des valeurs aberrantes\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    return outliers\n",
        "\n",
        "# Vérification des valeurs aberrantes dans la colonne 'price'\n",
        "price_outliers = detect_outliers(data, 'price')\n",
        "print(f\"Nombre de valeurs aberrantes dans 'price' : {len(price_outliers)}\")\n",
        "\n",
        "# Vérification des valeurs aberrantes dans la colonne 'quantity_x'\n",
        "quantity_outliers = detect_outliers(data, 'quantity_x')\n",
        "print(f\"Nombre de valeurs aberrantes dans 'quantity_x' : {len(quantity_outliers)}\")\n",
        "\n",
        "# Filtrage des données aberrantes en excluant les valeurs en dehors des bornes\n",
        "data_filtered = data[\n",
        "    (data['price'] >= data['price'].quantile(0.25) - 1.5 * (data['price'].quantile(0.75) - data['price'].quantile(0.25))) &\n",
        "    (data['price'] <= data['price'].quantile(0.75) + 1.5 * (data['price'].quantile(0.75) - data['price'].quantile(0.25))) &\n",
        "    (data['quantity_x'] >= data['quantity_x'].quantile(0.25) - 1.5 * (data['quantity_x'].quantile(0.75) - data['quantity_x'].quantile(0.25))) &\n",
        "    (data['quantity_x'] <= data['quantity_x'].quantile(0.75) + 1.5 * (data['quantity_x'].quantile(0.75) - data['quantity_x'].quantile(0.25)))\n",
        "]\n",
        "\n",
        "# Vérification de la taille du dataset après filtrage\n",
        "print(f\"Taille du dataset après filtrage : {data_filtered.shape}\")\n",
        "\n",
        "# Affichage des premières lignes du dataset après le filtrage des valeurs aberrantes\n",
        "print(\"\\nDataset après filtrage des valeurs aberrantes :\")\n",
        "print(data_filtered.head())\n",
        "data=data_filtered\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkikqUpkvdNG",
        "outputId": "aabc39e2-9c9b-4f72-b820-291dddb5d5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de valeurs aberrantes dans 'price' : 1376\n",
            "Nombre de valeurs aberrantes dans 'quantity_x' : 2542\n",
            "Taille du dataset après filtrage : (11935, 23)\n",
            "\n",
            "Dataset après filtrage des valeurs aberrantes :\n",
            "  order.id order.line order.date customer.id_x product.id quantity_x  Prefix  \\\n",
            "0        1          1   1/7/2011             2         48          1    Mrs.   \n",
            "1        1          2   1/7/2011             2         52          1    Mrs.   \n",
            "2        2          1  1/10/2011            10         76          1     Ms.   \n",
            "3        2          2  1/10/2011            10         52          1     Ms.   \n",
            "5        3          2  1/10/2011             6         50          1    Miss   \n",
            "\n",
            "   FirstName  LastName    BirthDate  ...  AnnualIncome  TotalChildren  \\\n",
            "0      Alice     Smith   02/12/1988  ...         60000              2   \n",
            "1      Alice     Smith   02/12/1988  ...         60000              2   \n",
            "2      Fiona      Teal   12/09/1989  ...         46000              1   \n",
            "3      Fiona      Teal   12/09/1989  ...         46000              1   \n",
            "5       Jane      Blue   14/04/1995  ...         32000              0   \n",
            "\n",
            "   EducationLevel  Occupation  HomeOwner                model category1  \\\n",
            "0        Master's      Doctor         No      Jekyll Carbon 2  Mountain   \n",
            "1        Master's      Doctor         No     Trigger Carbon 2  Mountain   \n",
            "2     Associate's    Engineer        Yes  Beast of the East 1  Mountain   \n",
            "3     Associate's    Engineer        Yes     Trigger Carbon 2  Mountain   \n",
            "5     Associate's     Student         No      Jekyll Carbon 4  Mountain   \n",
            "\n",
            "       category2     frame price  \n",
            "0  Over Mountain    Carbon  6070  \n",
            "1  Over Mountain    Carbon  5970  \n",
            "2          Trail  Aluminum  2770  \n",
            "3  Over Mountain    Carbon  5970  \n",
            "5  Over Mountain    Carbon  3200  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encodage des variables catégorielles :"
      ],
      "metadata": {
        "id": "r_f6bNDkwJ6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste des colonnes catégorielles pertinentes\n",
        "categorical_cols_to_encode = ['category1', 'category2', ' Occupation', ' HomeOwner',\n",
        "                              ' EducationLevel', ' MaritalStatus', ' Gender', 'frame']\n",
        "\n",
        "# Encodage de fréquence pour chaque colonne catégorielle pertinente\n",
        "for col in categorical_cols_to_encode:\n",
        "    if col in data.columns:\n",
        "        # Remplacer chaque catégorie par la fréquence d'apparition de la catégorie\n",
        "        freq_encoding = data[col].value_counts(normalize=True)\n",
        "        data[col] = data[col].map(freq_encoding)\n",
        "\n",
        "# Affichage des premières lignes du dataset après encodage\n",
        "print(\"\\nDataset après encodage de fréquence :\")\n",
        "print(data.head())\n",
        "\n",
        "# Affichage de la taille du dataset après encodage\n",
        "print(f\"\\nTaille du dataset après encodage : {data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNaPfo2TwBPD",
        "outputId": "a166cae1-a724-4bca-e63e-75dbfb21255b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset après encodage de fréquence :\n",
            "  order.id order.line order.date customer.id_x product.id quantity_x  Prefix  \\\n",
            "0        1          1   1/7/2011             2         48          1    Mrs.   \n",
            "1        1          2   1/7/2011             2         52          1    Mrs.   \n",
            "2        2          1  1/10/2011            10         76          1     Ms.   \n",
            "3        2          2  1/10/2011            10         52          1     Ms.   \n",
            "5        3          2  1/10/2011             6         50          1    Miss   \n",
            "\n",
            "   FirstName  LastName    BirthDate  ...   AnnualIncome   TotalChildren  \\\n",
            "0      Alice     Smith   02/12/1988  ...          60000               2   \n",
            "1      Alice     Smith   02/12/1988  ...          60000               2   \n",
            "2      Fiona      Teal   12/09/1989  ...          46000               1   \n",
            "3      Fiona      Teal   12/09/1989  ...          46000               1   \n",
            "5       Jane      Blue   14/04/1995  ...          32000               0   \n",
            "\n",
            "   EducationLevel  Occupation  HomeOwner                model  category1  \\\n",
            "0        0.151571    0.056473   0.364474      Jekyll Carbon 2   0.502472   \n",
            "1        0.151571    0.056473   0.364474     Trigger Carbon 2   0.502472   \n",
            "2        0.252367    0.192794   0.635526  Beast of the East 1   0.502472   \n",
            "3        0.252367    0.192794   0.635526     Trigger Carbon 2   0.502472   \n",
            "5        0.252367    0.019690   0.364474      Jekyll Carbon 4   0.502472   \n",
            "\n",
            "   category2    frame  price  \n",
            "0   0.064684  0.48362   6070  \n",
            "1   0.064684  0.48362   5970  \n",
            "2   0.134227  0.51638   2770  \n",
            "3   0.064684  0.48362   5970  \n",
            "5   0.064684  0.48362   3200  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Taille du dataset après encodage : (11935, 23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n",
            "<ipython-input-10-e1e69120d802>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = data[col].map(freq_encoding)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion la colonne 'order.date' en format datetime\n",
        "data['order.date'] = pd.to_datetime(data['order.date'])\n",
        "\n",
        "# Création d'une matrice client-produit basée sur l'historique des achats\n",
        "# La matrice contient les clients en lignes et les produits en colonnes avec les quantités achetées comme valeurs\n",
        "purchase_matrix = data.pivot_table(index='customer.id_x', columns='product.id', values='quantity_x', aggfunc='sum', fill_value=0)\n",
        "\n",
        "# Visualisation un échantillon de la matrice client-produit (facultatif)\n",
        "print(\"Aperçu de la matrice client-produit :\")\n",
        "print(purchase_matrix.head())\n",
        "\n",
        "# Définition le modèle KNN pour trouver les clients les plus similaires\n",
        "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "knn.fit(purchase_matrix)\n",
        "\n",
        "# Fonction pour recommander des produits à un client spécifique\n",
        "def recommend_products(customer_id, n_neighbors=5, n_recommendations=5):\n",
        "    # les clients les plus proches\n",
        "    distances, indices = knn.kneighbors(purchase_matrix.loc[[customer_id]], n_neighbors=n_neighbors+1)\n",
        "\n",
        "    # Exclure le client lui-même en prenant les autres voisins\n",
        "    similar_customers = indices.flatten()[1:]\n",
        "\n",
        "    # Agrégation les achats des clients similaires\n",
        "    similar_purchases = purchase_matrix.iloc[similar_customers].mean(axis=0)\n",
        "\n",
        "    # Filtrage les produits que le client n'a pas encore achetés\n",
        "    customer_purchases = purchase_matrix.loc[customer_id]\n",
        "    recommendations = similar_purchases[customer_purchases == 0]\n",
        "\n",
        "    # Trie les recommandations en fonction des scores moyens d'achat\n",
        "    recommended_products = recommendations.sort_values(ascending=False).head(n_recommendations)\n",
        "    return recommended_products\n",
        "\n",
        "# Exemple de recommandation pour un client (par exemple, client avec ID 1)\n",
        "recommendations = recommend_products(customer_id=1, n_neighbors=5, n_recommendations=5)\n",
        "print(\"\\nProduits recommandés pour le client 1 :\")\n",
        "print(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7PhmuH4tGjo",
        "outputId": "feb7a66f-4e64-4e13-8316-d5a2e52c0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aperçu de la matrice client-produit :\n",
            "product.id     4   5   6   7   8   9   10  11  12  13  ...  88  89  90  91  \\\n",
            "customer.id_x                                          ...                   \n",
            "1               5   6   2   3   1   1   0   2   3   2  ...   3   3   3   1   \n",
            "2               8   7  10   7   0   0   1   3   6  10  ...   6   9  14  12   \n",
            "3               4   3   1   5   0   2   4   4   5   7  ...   1   1   1   2   \n",
            "4               2   1   1   3   1   4   1   3   3   4  ...   5   5   4   6   \n",
            "5               4   5   2   5   1   3   6   6   4   9  ...   0   0   1   1   \n",
            "\n",
            "product.id     92  93  94  95  96  97  \n",
            "customer.id_x                          \n",
            "1               3   6   5   1   0   1  \n",
            "2               8   5   7   6   6   7  \n",
            "3               0   0   0   1   0   1  \n",
            "4               4   8   3   4   3   3  \n",
            "5               1   0   0   0   0   0  \n",
            "\n",
            "[5 rows x 86 columns]\n",
            "\n",
            "Produits recommandés pour le client 1 :\n",
            "product.id\n",
            "96    17.6\n",
            "21     9.8\n",
            "42     9.2\n",
            "35     9.2\n",
            "20     8.2\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b7a00ae37f26>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['order.date'] = pd.to_datetime(data['order.date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2rLeVwzwhjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}